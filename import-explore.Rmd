---
title: "UK road surface area: Part 1"
author: "Mark Ruddy"
date: "2017-02-27"
output: html_notebook
bibliography: /Users/markruddy/Documents/Research/Data/Bibliography/bibliodb.bib
---

This is post is the first in a series that will look at the amount of land space the UK has handed over as roads for motor vehicles. I'm not a transport professional but one of the things that interests me is the urban environment and how we travel around it. I also like doing data science and needed a project to flex my muscles after a few months away from coding. 

In this post I'll explain some background and get hold of some raw data. Later posts will contain more meat and bones data analysis.

## Roads and the places we live

I use whatever type of transport seems best - car, bus, train, hovercraft (actually not hovercraft) - depending on what I have to do and how far I have to go. But I mainly ride a bike and walk because they tend to be the most convenient and attractive modes. It's pretty evident that building roads for motor vehicles - not pedestrians or bicycles - is central to how our world has developed [^1]. The benefits to economies and quality of life this brings are set against an escalating series of problems: local air pollution, CO2 emissions, sedentary lifestyle issues, and road traffic mortality. There's a need for an urgent, fundamental shift away from decades of road-centred policy choices that have shaped the places we live in. Unfortunatley, legacy issues of [car dependency](https://en.wikipedia.org/wiki/Automobile_dependency) are hard to overcome and there is generally strong [local opposition](http://www.cs11.london/) to all but the weakest attempts to take road space from motor vehicles and give it to pedestrians and bicycle users.

One aspect of how road design impacts people is the amount of space given over to motor vehicles, especially in places where people live. The design of our public space influences so much about society - culture, economy, well-being - and road infrastructure is the portion of public space that [frames everything else](https://www.theguardian.com/books/2011/oct/14/jane-jacobs-death-and-life-rereading) [@jacobs:1961aa]. In fact, increasing numbers of cars mean that not only road space but duplicated [parking space](https://aseasyasridingabike.wordpress.com/2012/09/04/the-effect-of-private-car-dependence-on-land-use/) is also needed, seizing even more land.

Electric or hydrogen-powered vehicles may provide a solution to pollution and transport sector CO2 emissions, but the other [externalities](https://en.wikipedia.org/wiki/Externalities_of_automobiles) associated with motorised transport remain. Electric cars are just as capable of killing and seriously injuring people or dividing neighbourhoods - see this lovely graphic in Figure 1 by @appleyard:1981aa - as petrol-powered ones.

<figure class="align-centre">
  <a href="xresources/assets/images/geo-science/ois-plot.png"><img src="xresources/assets/images/general/appleyard-1981-fig3.png" alt="@appleyard:1981aa. Intra-street social connections with differing traffic volumes."></a>
  <figcaption>Figure 1. @appleyard:1981aa. Intra-street social connections with differing traffic volumes.</figcaption>
</figure>


## What is the surface area of the UK road network?

It was a conversation with my 6 year-old daughter that got me to thinking about exactly how much of the surface area of the places we live in is occupied by roads. I have a little time on my hands at the moment so decided to try and work it out. Here's two broad aims for what I want to achieve:

1. How much surface area is taken up by the UK road network?
2. How does this vary spatially at different scales?

## Data

Some googling uncovered a few datasets that might be useful. Ideally we'd want to use actual measurements of both road length and width. This is available from the [Ordnance Survey (OS)](https://www.ordnancesurvey.co.uk/), but the OS's [MasterMap](https://www.ordnancesurvey.co.uk/business-and-government/products/os-mastermap-highways-network-routing-asset-management-information.html) product costs £££s. There's no alternative open access datasets with length and widths (that I can find) so we'll have to take another approach.

### Road length datasets

Having no readily available road length with measured width data, the alternative is to use road length data with assumed widths dependant on the type of road (motorway, dual carriageway, singel carriage way, etc.). A number of option for obtaining purely road length data.

*Office for National Statistics*    

The 'official' source of information on this for the UK is the [Office for National Statistics (ONS)](https://www.gov.uk/government/statistical-data-sets/rdl02-road-lengths-kms). Figures on road length are presented for all road types, split by Local Authority, from 2005 to 2015. Local Authority areas are fairly large and inconsistently sized, so comparing between them is far from ideal, and there's no opportunity to drill down into finer grained geographic detail.

A supplement also lists road lengths, with various gaps, dating back to 1914. All are available under the Open Government Licence v3.0 ([OGL](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/)). 

*Ordnance Survey*    

The OS [Open Roads](https://www.ordnancesurvey.co.uk/business-and-government/products/os-open-roads.html) product is a spatial vector point and line dataset covering the whole of the UK, with roads coded by [class](https://www.ordnancesurvey.co.uk/docs/user-guides/os-open-roads-user-guide.pdf). Like the ONS data this is made available under OGL, but with a required attribution to the OS. Open Roads contains all roads excluding ['private roads and shorter cul-de-sacs'](https://www.ordnancesurvey.co.uk/business-and-government/products/os-open-roads.html), which should be a negibible omission in the context of what we want to achieve. This spatial dataset could be analysed on whatever level of geographic detail required - in contrast with the ONS data. 

*OpenStreeMap*    

[OpenStreetMap](https://www.openstreetmap.org) (OSM) is a digital map built through [volunteered geographic information](https://en.wikipedia.org/wiki/Volunteered_geographic_information) (VGI), freely available under the [Open Database Licence](http://wiki.osmfoundation.org/wiki/Licence). Roads are represented spatially as lines with a width attribute [sometimes](http://stackoverflow.com/a/25330995/2802810) - not always - present. The quality and coverage of OSM is often very good [@haklay:2010aa] but the risks of gaps in coverage make it unsuitable as a main dataset for our task. 

### Approach

The ONS and OS Open Roads datasets look to be useful. The ONS estimate includes OS data and additionally draws on information from Local Authorities, the Scottish and Welsh governments, and the Highways Agency. Although, with ONS there's no opportunity to do more detailed geographic analysis. 

Both datasets require assumptions on the widths of different road types, which we'll look at in a later post. I have an initial thought that although the OSM include an optional width attribute, where width is present it might be useful for sense-checking (?).

As a first pass let's use the ONS data and have a go with OS Open Roads later. I'll be using R to import, tidy, and explore the data. First thing, import.


## Wrangling ONS road length

### Import 

The ONS dataset is delivered as an OpenOffice .ods spreadsheet. We'll bring this into R for flexibility and reproducibility.

There's no substitute for opening a spreadsheet to quickly get a grasp on how much effort is needed to import it into R. Some specific issues to note with this dataset are:

* There are 6 rows to skip before the dataset begins.
* There are rows of meta-data below cells containing the dataset.
* There are twenty worksheets containing different types of road length information by year. Those sheets with names prefixed "RDL0202a"" contain Motorway, 'A' road, and Minor road data broken down by Local authority. These eleven sheets (years) are the data we're interested in.
* There are blank columns within each sheet that seem to serve an aesthetic purpose, separating groups of road classes. 
* Data extend over different cell ranges for different sheets.

So, this is not at all tidy and needs a fair bit of work to lick it into shape.

``` {r packages}
## Load packages
library(readODS)
library(httr)
```

```{r get-data}
## Get .ods file and save 
url <- "https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/523715/rdl0202.ods"

GET(url, write_disk("./ONS-GB-roads.ods", overwrite = T))
```


```{r read-sheets}
## Get sheet names we're interested in
path <- "./ONS-GB-roads.ods"
sheets <- ods_sheets(path)
my.sheets <- sheets[grepl("RDL0202a", sheets)] 
rm(sheets)

## Function to call read_ods for each sheet
ons.call <- function(sheet) {
  read_ods(path, sheet = sheet, col_names = TRUE, skip = 6)
}

## Read sheets as list of dfs 
rdl.list <- lapply(my.sheets, ons.call)
```


Each worksheet is read-in to R as a separate dataframe element within a list. These dataframes have slightly different structures, and we need to make them the same in order to combine them all together and make something 'tidy' [@tidy-data] for analysis. 

Some specific actions:

1. Add a year column to each list element.
2. Remove empty columns.
3. Remove non-data space below dataset.
4. Harmonise rows between sheets.
5. Combine dataframe elements from within list and make tidy.

### Add year 

```{r add-year}
## Add column with year to each df
years <- unlist(regmatches(my.sheets, gregexpr("(?<=\\().*?(?=\\))", my.sheets, perl=T))) ## Get the years for each sheet
rdl.list <- Map(cbind, rdl.list, years)
rdl.list <- lapply(rdl.list, function(x) {colnames(x)[ncol(x)] <- "Year"; x})

## Name df list elements
names(rdl.list) <- years
```


```{r check-year-sheet, include=FALSE}
## Cross check the year added to the dfs. Compare a column of road length values between sheet and df for match.

## Pick worksheet to cross check
chk.yr <- my.sheets[grepl("2010", my.sheets)] ## Get sheet we're interested in checking
chk.list <- lapply(chk.yr, ons.call) ## List of dfs to check

## Pick df from df list for cross check
chk.2010 <- rdl.list["2010"]

## Get Total road length from df and sheet and compare
identical(chk.2010[[1]][ncol(chk.2010[[1]])-1], chk.list[[1]][ncol(chk.list[[1]])])
```

```{r clean-up1}
rm(list=setdiff(ls(), "rdl.list"))
```


### Remove empty columns

```{r tidy-packages}
library(tidyverse)
```

```{r remove-empty-columns}
## Function to find NA columns in dataframe
na.cols <- function(df) {
  df.nas <- vapply(df, function(x) all(is.na(x)), logical(1))
  df.clean <- df[,!df.nas]
  df.clean
}

## lapply over list of dfs
rdl.list.full <- lapply(rdl.list, na.cols)

## Clean up 
rm(na.cols)
```


### Remove non-data space below dataset.

Metadata from each worksheet are found in the first and penultimate column and consist of long strings of text or NAs that extend partially or fully across the row. Most columns don't contain any metadata so the non-data rows at the end of the dataframe can be dropped by filtering out NAs from a column such as 'Region'.

```{r clean-below-data}
## Drop all NA rows in Region column
rdl.list.full <- lapply(rdl.list.full, function(x) x[!is.na(x$Region),])
```


### Harmonise rows between sheets

Dataframes between 2009-2015 have 206 rows but ones for 2005-2008 have 204 rows. What's causing this? The dataset is a summary of road lengths broken down by Local Authority, so Local Authority should be a 'key' between datasets and any differences in numbers of rows should be reflected in Local Authority values.


```{r diffs-toy}
## Toy example
tdf1 <- tibble(key = 1:4, x1 = LETTERS[1:4], x2 = LETTERS[2:5])
tdf2 <- tibble(key = 1:4, x1 = LETTERS[1:4], x2 = LETTERS[3:6])
tdf3 <- tibble(key = 1:4, x1 = LETTERS[c(1:3,5)], x2 = LETTERS[4:7])
toy.list <- list(tdf1,tdf2, tdf3)
names(toy.list) <- c("2000","2001","2002")

## Use dplyr:: and tidy:: to count values in grouped rows 
toy.df <- lapply(toy.list, `[[`, 2) %>% 
  data.frame

toy.count <- toy.df %>% 
  rownames_to_column("key") %>% 
  gather(x, value, -key) %>% 
  group_by(key) %>% 
  count(value) %>% 
  filter(n < ncol(toy.df))
```


```{r row-differences}
## Check for difference between Local Authorities *within* the 2005-2008 or 2009-2015 groups

## 2005-2008
rdl.1 <- rdl.list.full[c("2005", "2006", "2007", "2008")]


## Function to find differences between columns in a list of dataframes
## 
dflist.col.diffs <- function(dfl) { # x=list of dfs with element names
  comb <- combn(names(dfl), 2) # combinations of dataframes
  a.name <- comb[1,]
  b.name <- comb[2,]
  
  ## Funciton to compare contents of 2 columns from dataframe list
  compare.cols <- function(a.name, b.name) { # 2 vectors from list name combinations
    
  
  
  }
  
  
}

  
rdl.1 %>% 

```


<!-- post-2009:  -->
<!--   - Cheshire UA is split into Cheshire East UA, and Cheshire West and Chester UA from 2009. -->
<!--   - Bedfordshire is split into Bedford UA and Central Bedfordshire UA from 2009.  -->
<!-- 5. Harmonise columns: -->
<!--   - From 2013 to 2015 - Rural 'C' and 'U', and Urban 'C' and 'U' are combined from 2013. -->




## Bringing the whole road length dataset together

What are the steps that need to be taken to combine all the road length data together into a single dataset?



```{r tidy}
head(rdl.list[[1]])
lapply()

# rdl = do.call("rbind.data.frame", rdl.list) ## combine dfs from list
```

<!--* The cell range of the dataset (including column names) is:
  * A7:Z211 for 2005 to 2008; 
  * A7:Z213 from 2009 to 2012 
    - This is because:
    - Rural 'C' and 'U', and Urban 'C' and 'U' roads are separate up to 2013 but combined afterwards.
    - Cheshire UA is split into Cheshire East UA, and Cheshire West and Chester UA after 2009.
    - Bedfordshire is split into Bedford UA and Central Bedfordshire UA after 2009.
--> 



## References





[^1]: [Although they were originally built for bicycles](http://www.roadswerenotbuiltforcars.com/)


s